{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer-PPO Portfolio Optimization with Precious Metals\n",
    "\n",
    "This notebook combines Transformer-PPO reinforcement learning for portfolio optimization with:\n",
    "- **Dynamic NIFTY 50 stock selection** (top 15 by quarterly returns)\n",
    "- **Precious metals ETFs**: GOLDBEES and SILVERBEES\n",
    "- **17-asset portfolio** optimized using PPO\n",
    "\n",
    "## Sections\n",
    "1. Setup and Imports\n",
    "2. Data Fetching (yfinance)\n",
    "3. Dynamic Stock Selection (Quarterly Returns)\n",
    "4. Feature Engineering (ATR, MFI, Technical Indicators)\n",
    "5. Transformer-PPO Model Setup\n",
    "6. Environment Configuration\n",
    "7. Training Loop\n",
    "8. Backtesting\n",
    "9. Performance Visualization\n",
    "10. Final Results & Asset Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install yfinance pandas-ta gymnasium torch numpy pandas matplotlib seaborn plotly tqdm scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Import transformer-PPO components\n",
    "from models.ppo_agent import PPOAgent\n",
    "from environment.trading_env import TradingEnvironment\n",
    "from training.trainer import PPOTrainer\n",
    "from data.features import FeatureEngineering\n",
    "from data.preprocessing import FeaturePreprocessor\n",
    "from backtesting.engine import BacktestEngine\n",
    "from backtesting.metrics import PerformanceMetrics\n",
    "from backtesting.visualization import PerformanceVisualizer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì All imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    # Data parameters\n",
    "    'start_date': '2020-01-01',\n",
    "    'end_date': '2024-12-31',\n",
    "    'num_stocks': 15,  # Top N stocks by quarterly returns\n",
    "    'total_assets': 17,  # 15 stocks + 2 ETFs (GOLDBEES, SILVERBEES)\n",
    "    \n",
    "    # Stock selection\n",
    "    'selection_period': 63,  # 3 months (approximately 63 trading days)\n",
    "    'rebalance_frequency': 'quarterly',  # How often to reselect stocks\n",
    "    \n",
    "    # Model parameters\n",
    "    'stock_embedding_dim': 64,\n",
    "    'market_embedding_dim': 32,\n",
    "    'num_transformer_heads': 4,\n",
    "    'num_transformer_layers': 2,\n",
    "    'policy_hidden_dim': 64,\n",
    "    'value_hidden_dim': 128,\n",
    "    'dropout': 0.1,\n",
    "    'max_weight': 0.25,  # Maximum weight per asset\n",
    "    \n",
    "    # Training parameters\n",
    "    'n_episodes': 100,\n",
    "    'episode_length': 252,  # One year\n",
    "    'learning_rate': 3e-4,\n",
    "    'gamma': 0.99,\n",
    "    'gae_lambda': 0.95,\n",
    "    'clip_epsilon': 0.2,\n",
    "    'value_coef': 0.5,\n",
    "    'entropy_coef': 0.01,\n",
    "    'batch_size': 64,\n",
    "    'buffer_size': 2048,\n",
    "    \n",
    "    # Environment parameters\n",
    "    'transaction_cost': 0.001,\n",
    "    'turnover_penalty': 0.0005,\n",
    "    'initial_cash': 1000000.0,\n",
    "    \n",
    "    # Feature parameters\n",
    "    'lookback_window': 20,\n",
    "    \n",
    "    # Device\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Fetching with yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 NIFTY 50 Stock Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIFTY 50 constituents (as of 2024)\n",
    "NIFTY_50_STOCKS = [\n",
    "    'ADANIENT', 'ADANIPORTS', 'APOLLOHOSP', 'ASIANPAINT', 'AXISBANK',\n",
    "    'BAJAJ-AUTO', 'BAJFINANCE', 'BAJAJFINSV', 'BPCL', 'BHARTIARTL',\n",
    "    'BRITANNIA', 'CIPLA', 'COALINDIA', 'DIVISLAB', 'DRREDDY',\n",
    "    'EICHERMOT', 'GRASIM', 'HCLTECH', 'HDFCBANK', 'HDFCLIFE',\n",
    "    'HEROMOTOCO', 'HINDALCO', 'HINDUNILVR', 'ICICIBANK', 'ITC',\n",
    "    'INDUSINDBK', 'INFY', 'JSWSTEEL', 'KOTAKBANK', 'LT',\n",
    "    'M&M', 'MARUTI', 'NTPC', 'NESTLEIND', 'ONGC',\n",
    "    'POWERGRID', 'RELIANCE', 'SBILIFE', 'SBIN', 'SUNPHARMA',\n",
    "    'TCS', 'TATACONSUM', 'TATAMOTORS', 'TATASTEEL', 'TECHM',\n",
    "    'TITAN', 'ULTRACEMCO', 'UPL', 'WIPRO', 'LTIM'\n",
    "]\n",
    "\n",
    "# Add .NS suffix for NSE\n",
    "NIFTY_50_TICKERS = [f\"{stock}.NS\" for stock in NIFTY_50_STOCKS]\n",
    "\n",
    "# Precious metals ETFs\n",
    "PRECIOUS_METALS = ['GOLDBEES.NS', 'SILVERBEES.NS']\n",
    "\n",
    "print(f\"NIFTY 50 Universe: {len(NIFTY_50_TICKERS)} stocks\")\n",
    "print(f\"Precious Metals ETFs: {PRECIOUS_METALS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Download Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(tickers: List[str], start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download stock data from yfinance.\n",
    "    \n",
    "    Args:\n",
    "        tickers: List of stock tickers\n",
    "        start_date: Start date (YYYY-MM-DD)\n",
    "        end_date: End date (YYYY-MM-DD)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with OHLCV data\n",
    "    \"\"\"\n",
    "    print(f\"Downloading data for {len(tickers)} tickers...\")\n",
    "    \n",
    "    data_list = []\n",
    "    failed_tickers = []\n",
    "    \n",
    "    for ticker in tqdm(tickers, desc=\"Downloading\"):\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "            \n",
    "            if df.empty or len(df) < 100:\n",
    "                failed_tickers.append(ticker)\n",
    "                continue\n",
    "            \n",
    "            df = df.reset_index()\n",
    "            df['Ticker'] = ticker\n",
    "            df['Stock'] = ticker.replace('.NS', '')\n",
    "            \n",
    "            # Handle timezone\n",
    "            if 'Date' in df.columns:\n",
    "                if df['Date'].dt.tz is not None:\n",
    "                    df['Date'] = df['Date'].dt.tz_localize(None)\n",
    "            \n",
    "            data_list.append(df[['Date', 'Stock', 'Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to download {ticker}: {e}\")\n",
    "            failed_tickers.append(ticker)\n",
    "            continue\n",
    "    \n",
    "    if failed_tickers:\n",
    "        print(f\"\\n‚ö†Ô∏è  Failed tickers ({len(failed_tickers)}): {failed_tickers[:5]}...\")\n",
    "    \n",
    "    if not data_list:\n",
    "        raise ValueError(\"No data downloaded successfully!\")\n",
    "    \n",
    "    combined_df = pd.concat(data_list, ignore_index=True)\n",
    "    combined_df = combined_df.sort_values(['Date', 'Stock']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n‚úì Downloaded {combined_df['Stock'].nunique()} stocks\")\n",
    "    print(f\"  Date range: {combined_df['Date'].min().date()} to {combined_df['Date'].max().date()}\")\n",
    "    print(f\"  Total records: {len(combined_df):,}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# Download NIFTY 50 data\n",
    "print(\"=\" * 80)\n",
    "print(\"DOWNLOADING NIFTY 50 DATA\")\n",
    "print(\"=\" * 80)\n",
    "nifty_data = download_stock_data(NIFTY_50_TICKERS, CONFIG['start_date'], CONFIG['end_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dynamic Stock Selection (Quarterly Returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quarterly_returns(df: pd.DataFrame, lookback_days: int = 63) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate quarterly (3-month) returns for each stock.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with stock data\n",
    "        lookback_days: Number of days for quarterly calculation (default 63 ~ 3 months)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with quarterly returns\n",
    "    \"\"\"\n",
    "    returns_list = []\n",
    "    \n",
    "    for stock in df['Stock'].unique():\n",
    "        stock_data = df[df['Stock'] == stock].sort_values('Date').copy()\n",
    "        \n",
    "        if len(stock_data) < lookback_days:\n",
    "            continue\n",
    "        \n",
    "        # Calculate quarterly return (last 3 months)\n",
    "        latest_price = stock_data['Close'].iloc[-1]\n",
    "        past_price = stock_data['Close'].iloc[-lookback_days]\n",
    "        quarterly_return = (latest_price / past_price - 1) * 100\n",
    "        \n",
    "        returns_list.append({\n",
    "            'Stock': stock,\n",
    "            'QuarterlyReturn': quarterly_return,\n",
    "            'LatestPrice': latest_price,\n",
    "            'DataPoints': len(stock_data)\n",
    "        })\n",
    "    \n",
    "    returns_df = pd.DataFrame(returns_list)\n",
    "    returns_df = returns_df.sort_values('QuarterlyReturn', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return returns_df\n",
    "\n",
    "\n",
    "def select_top_performers(df: pd.DataFrame, returns_df: pd.DataFrame, top_n: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Select top N stocks by quarterly returns.\n",
    "    \n",
    "    Args:\n",
    "        df: Full stock data\n",
    "        returns_df: DataFrame with quarterly returns (sorted)\n",
    "        top_n: Number of top stocks to select\n",
    "        \n",
    "    Returns:\n",
    "        Filtered DataFrame with top performers\n",
    "    \"\"\"\n",
    "    top_stocks = returns_df.head(top_n)['Stock'].tolist()\n",
    "    filtered_df = df[df['Stock'].isin(top_stocks)].copy()\n",
    "    \n",
    "    return filtered_df, top_stocks\n",
    "\n",
    "\n",
    "# Calculate quarterly returns\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DYNAMIC STOCK SELECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "quarterly_returns = calculate_quarterly_returns(nifty_data, CONFIG['selection_period'])\n",
    "\n",
    "print(f\"\\nTop 15 Stocks by Quarterly Returns:\")\n",
    "print(\"-\" * 60)\n",
    "print(quarterly_returns.head(15).to_string(index=False))\n",
    "\n",
    "# Select top 15 performers\n",
    "selected_stock_data, selected_stocks = select_top_performers(\n",
    "    nifty_data, \n",
    "    quarterly_returns, \n",
    "    CONFIG['num_stocks']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Selected {len(selected_stocks)} top-performing stocks:\")\n",
    "print(f\"  {', '.join(selected_stocks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Add Precious Metals ETFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download precious metals ETF data\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DOWNLOADING PRECIOUS METALS ETFs\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "precious_metals_data = download_stock_data(\n",
    "    PRECIOUS_METALS, \n",
    "    CONFIG['start_date'], \n",
    "    CONFIG['end_date']\n",
    ")\n",
    "\n",
    "# Combine selected stocks with precious metals\n",
    "all_assets_data = pd.concat([selected_stock_data, precious_metals_data], ignore_index=True)\n",
    "all_assets_data = all_assets_data.sort_values(['Date', 'Stock']).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úì Total portfolio assets: {all_assets_data['Stock'].nunique()}\")\n",
    "print(f\"  - Stocks: {len(selected_stocks)}\")\n",
    "print(f\"  - ETFs: {len(PRECIOUS_METALS)}\")\n",
    "print(f\"\\n  Assets: {sorted(all_assets_data['Stock'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Technical Indicators (ATR, MFI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate Average True Range (ATR).\n",
    "    \"\"\"\n",
    "    high_low = df['High'] - df['Low']\n",
    "    high_close = np.abs(df['High'] - df['Close'].shift())\n",
    "    low_close = np.abs(df['Low'] - df['Close'].shift())\n",
    "    \n",
    "    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    atr = true_range.rolling(window=period).mean()\n",
    "    \n",
    "    return atr\n",
    "\n",
    "\n",
    "def calculate_mfi(df: pd.DataFrame, period: int = 14) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate Money Flow Index (MFI).\n",
    "    \"\"\"\n",
    "    typical_price = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "    money_flow = typical_price * df['Volume']\n",
    "    \n",
    "    # Positive and negative money flow\n",
    "    positive_flow = pd.Series(0.0, index=df.index)\n",
    "    negative_flow = pd.Series(0.0, index=df.index)\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        if typical_price.iloc[i] > typical_price.iloc[i-1]:\n",
    "            positive_flow.iloc[i] = money_flow.iloc[i]\n",
    "        elif typical_price.iloc[i] < typical_price.iloc[i-1]:\n",
    "            negative_flow.iloc[i] = money_flow.iloc[i]\n",
    "    \n",
    "    positive_mf = positive_flow.rolling(window=period).sum()\n",
    "    negative_mf = negative_flow.rolling(window=period).sum()\n",
    "    \n",
    "    mfi = 100 - (100 / (1 + positive_mf / (negative_mf + 1e-10)))\n",
    "    \n",
    "    return mfi\n",
    "\n",
    "\n",
    "def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add technical indicators to stock data.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    features_list = []\n",
    "    \n",
    "    for stock in tqdm(df['Stock'].unique(), desc=\"Computing indicators\"):\n",
    "        stock_data = df[df['Stock'] == stock].sort_values('Date').copy()\n",
    "        \n",
    "        # ATR\n",
    "        stock_data['ATR_14'] = calculate_atr(stock_data, period=14)\n",
    "        \n",
    "        # MFI\n",
    "        stock_data['MFI_14'] = calculate_mfi(stock_data, period=14)\n",
    "        \n",
    "        features_list.append(stock_data)\n",
    "    \n",
    "    return pd.concat(features_list, ignore_index=True)\n",
    "\n",
    "\n",
    "# Add technical indicators\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_assets_data = add_technical_indicators(all_assets_data)\n",
    "\n",
    "print(\"\\n‚úì Added technical indicators: ATR, MFI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Stock Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute stock features using existing FeatureEngineering class\n",
    "feature_eng = FeatureEngineering(lookback_window=CONFIG['lookback_window'])\n",
    "features_df = feature_eng.compute_stock_features(all_assets_data)\n",
    "\n",
    "print(f\"\\n‚úì Computed stock features\")\n",
    "print(f\"  Features: {[col for col in features_df.columns if col not in ['Date', 'Stock', 'Open', 'High', 'Low', 'Close', 'Volume']]}\")\n",
    "print(f\"  Shape: {features_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Market Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_market_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute market-level features.\n",
    "    \"\"\"\n",
    "    # Calculate equal-weighted market return\n",
    "    market_returns = df.groupby('Date')['Returns'].mean().reset_index()\n",
    "    market_returns.columns = ['Date', 'MarketReturn']\n",
    "    \n",
    "    # Market volatility\n",
    "    market_returns['MarketVolatility'] = market_returns['MarketReturn'].rolling(20).std()\n",
    "    \n",
    "    # Market momentum\n",
    "    market_returns['MarketMomentum_5'] = market_returns['MarketReturn'].rolling(5).mean()\n",
    "    market_returns['MarketMomentum_20'] = market_returns['MarketReturn'].rolling(20).mean()\n",
    "    \n",
    "    # Dispersion (cross-sectional std)\n",
    "    dispersion = df.groupby('Date')['Returns'].std().reset_index()\n",
    "    dispersion.columns = ['Date', 'MarketDispersion']\n",
    "    market_returns = market_returns.merge(dispersion, on='Date', how='left')\n",
    "    \n",
    "    return market_returns\n",
    "\n",
    "\n",
    "market_features = compute_market_features(features_df)\n",
    "\n",
    "print(f\"\\n‚úì Computed market features:\")\n",
    "print(f\"  {list(market_features.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge market features into stock data\n",
    "features_df = features_df.merge(market_features, on='Date', how='left')\n",
    "\n",
    "# Drop NaN rows (from rolling calculations)\n",
    "features_df = features_df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úì Prepared features:\")\n",
    "print(f\"  Shape: {features_df.shape}\")\n",
    "print(f\"  Date range: {features_df['Date'].min().date()} to {features_df['Date'].max().date()}\")\n",
    "print(f\"  Assets: {features_df['Stock'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Preprocessing and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "stock_feature_cols = [\n",
    "    'Returns', 'LogReturns', 'Momentum_5', 'Momentum_10', 'Momentum_20',\n",
    "    'Volatility_5', 'Volatility_10', 'Volatility_20',\n",
    "    'HighLow_Range', 'OpenClose_Range',\n",
    "    'Price_to_SMA5', 'Price_to_SMA10', 'Price_to_SMA20',\n",
    "    'Volume_Change', 'Volume_Ratio', 'RSI_14',\n",
    "    'ATR_14', 'MFI_14'\n",
    "]\n",
    "\n",
    "market_feature_cols = [\n",
    "    'MarketReturn', 'MarketVolatility',\n",
    "    'MarketMomentum_5', 'MarketMomentum_20',\n",
    "    'MarketDispersion'\n",
    "]\n",
    "\n",
    "# Use FeaturePreprocessor\n",
    "preprocessor = FeaturePreprocessor(\n",
    "    stock_feature_cols=stock_feature_cols,\n",
    "    market_feature_cols=market_feature_cols\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "stock_sequences, market_sequences, returns, dates, stock_names = preprocessor.prepare_sequences(\n",
    "    features_df\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Data preprocessed and normalized:\")\n",
    "print(f\"  Stock sequences shape: {stock_sequences.shape}\")\n",
    "print(f\"  Market sequences shape: {market_sequences.shape}\")\n",
    "print(f\"  Returns shape: {returns.shape}\")\n",
    "print(f\"  Number of timesteps: {len(dates)}\")\n",
    "print(f\"  Number of assets: {len(stock_names)}\")\n",
    "print(f\"  Stock names: {stock_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Trading Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trading environment\n",
    "env = TradingEnvironment(\n",
    "    stock_sequences=stock_sequences,\n",
    "    market_sequences=market_sequences,\n",
    "    returns=returns,\n",
    "    dates=dates,\n",
    "    transaction_cost=CONFIG['transaction_cost'],\n",
    "    turnover_penalty=CONFIG['turnover_penalty'],\n",
    "    initial_cash=CONFIG['initial_cash'],\n",
    "    normalize_rewards=True,\n",
    "    random_start=True,\n",
    "    episode_length=CONFIG['episode_length']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Trading environment created:\")\n",
    "print(f\"  Assets: {env.num_stocks}\")\n",
    "print(f\"  Stock features: {env.num_stock_features}\")\n",
    "print(f\"  Market features: {env.num_market_features}\")\n",
    "print(f\"  Episode length: {env.episode_length} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Initialize Transformer-PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PPO agent\n",
    "agent = PPOAgent(\n",
    "    num_stock_features=env.num_stock_features,\n",
    "    num_market_features=env.num_market_features,\n",
    "    num_stocks=env.num_stocks,\n",
    "    stock_embedding_dim=CONFIG['stock_embedding_dim'],\n",
    "    market_embedding_dim=CONFIG['market_embedding_dim'],\n",
    "    num_transformer_heads=CONFIG['num_transformer_heads'],\n",
    "    num_transformer_layers=CONFIG['num_transformer_layers'],\n",
    "    policy_hidden_dim=CONFIG['policy_hidden_dim'],\n",
    "    value_hidden_dim=CONFIG['value_hidden_dim'],\n",
    "    dropout=CONFIG['dropout'],\n",
    "    max_weight=CONFIG['max_weight'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in agent.parameters())\n",
    "trainable_params = sum(p.numel() for p in agent.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úì Transformer-PPO Agent initialized:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Device: {CONFIG['device']}\")\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = PPOTrainer(\n",
    "    agent=agent,\n",
    "    env=env,\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    gamma=CONFIG['gamma'],\n",
    "    gae_lambda=CONFIG['gae_lambda'],\n",
    "    clip_epsilon=CONFIG['clip_epsilon'],\n",
    "    value_coef=CONFIG['value_coef'],\n",
    "    entropy_coef=CONFIG['entropy_coef'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    buffer_size=CONFIG['buffer_size'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì PPO Trainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING TRANSFORMER-PPO AGENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "training_history = {\n",
    "    'episode': [],\n",
    "    'reward': [],\n",
    "    'length': [],\n",
    "    'sharpe': [],\n",
    "    'max_drawdown': []\n",
    "}\n",
    "\n",
    "for episode in tqdm(range(CONFIG['n_episodes']), desc=\"Training\"):\n",
    "    # Collect rollout\n",
    "    rollout_stats = trainer.collect_rollout(n_steps=CONFIG['buffer_size'])\n",
    "    \n",
    "    # Update policy\n",
    "    update_stats = trainer.update()\n",
    "    \n",
    "    # Get episode statistics\n",
    "    episode_stats = env.get_episode_statistics()\n",
    "    \n",
    "    # Log\n",
    "    training_history['episode'].append(episode)\n",
    "    training_history['reward'].append(rollout_stats['mean_reward'])\n",
    "    training_history['length'].append(rollout_stats['mean_length'])\n",
    "    training_history['sharpe'].append(episode_stats.get('sharpe_ratio', 0))\n",
    "    training_history['max_drawdown'].append(episode_stats.get('max_drawdown', 0))\n",
    "    \n",
    "    # Print progress\n",
    "    if (episode + 1) % 10 == 0:\n",
    "        print(f\"\\nEpisode {episode + 1}/{CONFIG['n_episodes']}\")\n",
    "        print(f\"  Reward: {rollout_stats['mean_reward']:.4f}\")\n",
    "        print(f\"  Sharpe: {episode_stats.get('sharpe_ratio', 0):.2f}\")\n",
    "        print(f\"  MaxDD: {episode_stats.get('max_drawdown', 0):.2%}\")\n",
    "        print(f\"  Policy Loss: {update_stats['policy_loss']:.4f}\")\n",
    "        print(f\"  Value Loss: {update_stats['value_loss']:.4f}\")\n",
    "\n",
    "print(\"\\n‚úì Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Rewards\n",
    "axes[0, 0].plot(training_history['episode'], training_history['reward'])\n",
    "axes[0, 0].set_title('Episode Reward')\n",
    "axes[0, 0].set_xlabel('Episode')\n",
    "axes[0, 0].set_ylabel('Mean Reward')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Sharpe ratio\n",
    "axes[0, 1].plot(training_history['episode'], training_history['sharpe'])\n",
    "axes[0, 1].set_title('Sharpe Ratio')\n",
    "axes[0, 1].set_xlabel('Episode')\n",
    "axes[0, 1].set_ylabel('Sharpe Ratio')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Max drawdown\n",
    "axes[1, 0].plot(training_history['episode'], training_history['max_drawdown'])\n",
    "axes[1, 0].set_title('Maximum Drawdown')\n",
    "axes[1, 0].set_xlabel('Episode')\n",
    "axes[1, 0].set_ylabel('Max Drawdown')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Episode length\n",
    "axes[1, 1].plot(training_history['episode'], training_history['length'])\n",
    "axes[1, 1].set_title('Episode Length')\n",
    "axes[1, 1].set_xlabel('Episode')\n",
    "axes[1, 1].set_ylabel('Days')\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create backtest engine\n",
    "backtest_engine = BacktestEngine(\n",
    "    agent=agent,\n",
    "    stock_sequences=stock_sequences,\n",
    "    market_sequences=market_sequences,\n",
    "    returns=returns,\n",
    "    dates=dates,\n",
    "    stock_names=stock_names,\n",
    "    transaction_cost=CONFIG['transaction_cost'],\n",
    "    initial_cash=CONFIG['initial_cash']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BACKTESTING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Run backtest\n",
    "backtest_results = backtest_engine.run_backtest(deterministic=True)\n",
    "\n",
    "print(f\"\\n‚úì Backtest completed\")\n",
    "print(f\"  Total days: {len(backtest_results['portfolio_values'])}\")\n",
    "print(f\"  Date range: {dates[0].date()} to {dates[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "metrics = PerformanceMetrics()\n",
    "performance = metrics.calculate_metrics(\n",
    "    portfolio_values=backtest_results['portfolio_values'],\n",
    "    dates=dates,\n",
    "    initial_cash=CONFIG['initial_cash']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nTotal Return: {performance['total_return']:.2%}\")\n",
    "print(f\"Annualized Return: {performance['annualized_return']:.2%}\")\n",
    "print(f\"Annualized Volatility: {performance['annualized_volatility']:.2%}\")\n",
    "print(f\"Sharpe Ratio: {performance['sharpe_ratio']:.2f}\")\n",
    "print(f\"Maximum Drawdown: {performance['max_drawdown']:.2%}\")\n",
    "print(f\"Calmar Ratio: {performance['calmar_ratio']:.2f}\")\n",
    "print(f\"Win Rate: {performance['win_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Portfolio Value Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio value over time\n",
    "visualizer = PerformanceVisualizer()\n",
    "visualizer.plot_portfolio_value(\n",
    "    portfolio_values=backtest_results['portfolio_values'],\n",
    "    dates=dates,\n",
    "    benchmark_values=None  # Can add NIFTY 50 benchmark\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2 Drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawdown chart\n",
    "visualizer.plot_drawdown(\n",
    "    portfolio_values=backtest_results['portfolio_values'],\n",
    "    dates=dates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3 Monthly Returns Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly returns\n",
    "portfolio_df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Value': backtest_results['portfolio_values']\n",
    "})\n",
    "portfolio_df['Date'] = pd.to_datetime(portfolio_df['Date'])\n",
    "portfolio_df = portfolio_df.set_index('Date')\n",
    "portfolio_df['Returns'] = portfolio_df['Value'].pct_change()\n",
    "\n",
    "# Resample to monthly\n",
    "monthly_returns = portfolio_df['Returns'].resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
    "monthly_returns_pivot = monthly_returns.to_frame()\n",
    "monthly_returns_pivot['Year'] = monthly_returns_pivot.index.year\n",
    "monthly_returns_pivot['Month'] = monthly_returns_pivot.index.month\n",
    "monthly_returns_pivot = monthly_returns_pivot.pivot(index='Year', columns='Month', values='Returns')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    monthly_returns_pivot * 100, \n",
    "    annot=True, \n",
    "    fmt='.1f', \n",
    "    cmap='RdYlGn', \n",
    "    center=0,\n",
    "    cbar_kws={'label': 'Return (%)'}\n",
    ")\n",
    "plt.title('Monthly Returns Heatmap (%)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Year')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Final Asset Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final portfolio weights\n",
    "final_weights = backtest_results['weights'][-1]\n",
    "\n",
    "# Create weights DataFrame\n",
    "weights_df = pd.DataFrame({\n",
    "    'Asset': stock_names,\n",
    "    'Weight': final_weights,\n",
    "    'Weight_Pct': final_weights * 100\n",
    "})\n",
    "weights_df = weights_df.sort_values('Weight', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL PORTFOLIO WEIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "print(weights_df.to_string(index=False))\n",
    "\n",
    "# Highlight precious metals\n",
    "gold_weight = weights_df[weights_df['Asset'] == 'GOLDBEES']['Weight_Pct'].values\n",
    "silver_weight = weights_df[weights_df['Asset'] == 'SILVERBEES']['Weight_Pct'].values\n",
    "\n",
    "print(f\"\\nüìä Precious Metals Allocation:\")\n",
    "if len(gold_weight) > 0:\n",
    "    print(f\"  GOLDBEES: {gold_weight[0]:.2f}%\")\n",
    "if len(silver_weight) > 0:\n",
    "    print(f\"  SILVERBEES: {silver_weight[0]:.2f}%\")\n",
    "    \n",
    "total_precious = (gold_weight[0] if len(gold_weight) > 0 else 0) + (silver_weight[0] if len(silver_weight) > 0 else 0)\n",
    "print(f\"  Total Precious Metals: {total_precious:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1 Weight Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of final weights\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Highlight precious metals with different colors\n",
    "colors = ['gold' if asset == 'GOLDBEES' else 'silver' if asset == 'SILVERBEES' else None \n",
    "          for asset in weights_df['Asset']]\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    weights_df['Weight'],\n",
    "    labels=weights_df['Asset'],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    startangle=90\n",
    ")\n",
    "\n",
    "# Enhance text\n",
    "for text in texts:\n",
    "    text.set_fontsize(10)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "ax.set_title('Final Portfolio Allocation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2 Weight Evolution Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weight evolution\n",
    "weights_over_time = np.array(backtest_results['weights'])\n",
    "\n",
    "# Plot for precious metals and top 5 stocks\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Find indices of precious metals and top stocks\n",
    "gold_idx = stock_names.index('GOLDBEES') if 'GOLDBEES' in stock_names else None\n",
    "silver_idx = stock_names.index('SILVERBEES') if 'SILVERBEES' in stock_names else None\n",
    "top_stocks_idx = weights_df.head(5)['Asset'].tolist()\n",
    "\n",
    "# Plot precious metals with bold lines\n",
    "if gold_idx is not None:\n",
    "    ax.plot(dates, weights_over_time[:, gold_idx], label='GOLDBEES', linewidth=2.5, color='gold')\n",
    "if silver_idx is not None:\n",
    "    ax.plot(dates, weights_over_time[:, silver_idx], label='SILVERBEES', linewidth=2.5, color='silver')\n",
    "\n",
    "# Plot top 5 stocks\n",
    "for stock in top_stocks_idx:\n",
    "    if stock not in ['GOLDBEES', 'SILVERBEES']:\n",
    "        idx = stock_names.index(stock)\n",
    "        ax.plot(dates, weights_over_time[:, idx], label=stock, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title('Portfolio Weight Evolution (Top Assets)', fontsize=14, fontweight='bold')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRANSFORMER-PPO PORTFOLIO OPTIMIZATION - SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìã Portfolio Composition:\")\n",
    "print(f\"  Total Assets: {len(stock_names)}\")\n",
    "print(f\"  - Stocks (Top 15 NIFTY 50): {len([s for s in stock_names if s not in ['GOLDBEES', 'SILVERBEES']])}\")\n",
    "print(f\"  - Precious Metals ETFs: {len([s for s in stock_names if s in ['GOLDBEES', 'SILVERBEES']])}\")\n",
    "\n",
    "print(\"\\nüìà Performance Summary:\")\n",
    "print(f\"  Period: {dates[0].date()} to {dates[-1].date()}\")\n",
    "print(f\"  Total Return: {performance['total_return']:.2%}\")\n",
    "print(f\"  Annualized Return: {performance['annualized_return']:.2%}\")\n",
    "print(f\"  Volatility: {performance['annualized_volatility']:.2%}\")\n",
    "print(f\"  Sharpe Ratio: {performance['sharpe_ratio']:.2f}\")\n",
    "print(f\"  Max Drawdown: {performance['max_drawdown']:.2%}\")\n",
    "\n",
    "print(\"\\nüèÜ Top 5 Holdings:\")\n",
    "for i, row in weights_df.head(5).iterrows():\n",
    "    symbol = 'ü•á' if row['Asset'] == 'GOLDBEES' else 'ü•à' if row['Asset'] == 'SILVERBEES' else 'üìä'\n",
    "    print(f\"  {symbol} {row['Asset']:<15} {row['Weight_Pct']:>6.2f}%\")\n",
    "\n",
    "print(\"\\nüíé Precious Metals Exposure:\")\n",
    "print(f\"  Total allocation: {total_precious:.2f}%\")\n",
    "if len(gold_weight) > 0:\n",
    "    print(f\"  - Gold (GOLDBEES): {gold_weight[0]:.2f}%\")\n",
    "if len(silver_weight) > 0:\n",
    "    print(f\"  - Silver (SILVERBEES): {silver_weight[0]:.2f}%\")\n",
    "\n",
    "print(\"\\n‚úì Analysis complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "checkpoint_path = '../checkpoints/transformer_ppo_precious_metals.pt'\n",
    "os.makedirs('../checkpoints', exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': agent.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'stock_names': stock_names,\n",
    "    'performance': performance,\n",
    "    'final_weights': weights_df.to_dict('records')\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(f\"‚úì Model saved to {checkpoint_path}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'PortfolioValue': backtest_results['portfolio_values']\n",
    "})\n",
    "results_df.to_csv('../results/transformer_ppo_precious_metals_results.csv', index=False)\n",
    "print(f\"‚úì Results saved to ../results/transformer_ppo_precious_metals_results.csv\")\n",
    "\n",
    "# Save weights\n",
    "weights_df.to_csv('../results/final_weights_precious_metals.csv', index=False)\n",
    "print(f\"‚úì Weights saved to ../results/final_weights_precious_metals.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
